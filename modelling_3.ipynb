{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "# import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Disables RDKit whiny logging.\n",
    "\"\"\"\n",
    "import rdkit.rdBase as rkrb\n",
    "import rdkit.RDLogger as rkl\n",
    "logger = rkl.logger()\n",
    "logger.setLevel(rkl.ERROR)\n",
    "rkrb.DisableLog('rdApp.error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the data preprocessed in USPTO_preprocessing.ipynb\n",
    "# There's around 500k reactions, and columns for reactant, product, solvent, reagent, etc.\n",
    "# So there's quite a bit more data than in Modelling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in pickled clean data\n",
    "cleaned_df = pd.read_pickle(f\"data/ORD_USPTO/cleaned_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the reaction classes\n",
    "rxn_classes_filename = '/Users/dsw46/nextmove/HazELNut/build/data/classified_rxn.smi'\n",
    "\n",
    "with open(rxn_classes_filename) as f:\n",
    "    lines = f.readlines()\n",
    "lines = [line.rstrip('\\n') for line in lines] # remove the \\n at the end of each line\n",
    "\n",
    "# create df of the reaction classes\n",
    "# 2 columns: mapped_rxn, rxn_classes\n",
    "rxns = []\n",
    "rxn_classes = []\n",
    "for line in lines:\n",
    "    try:\n",
    "        rxn, rxn_class = line.split(' ')\n",
    "        rxns += [rxn]\n",
    "        rxn_classes += [rxn_class]\n",
    "    except AttributeError:\n",
    "        continue\n",
    "    \n",
    "rxn_classes_df = pd.DataFrame(list(zip(rxns, rxn_classes)),\n",
    "               columns =['mapped_rxn', 'rxn_class'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the two dfs\n",
    "data_df_temp = cleaned_df.merge(rxn_classes_df, how='inner', left_on='mapped_rxn_0', right_on='mapped_rxn')\n",
    "len(data_df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526999\n"
     ]
    }
   ],
   "source": [
    "# I used the following command to generate the rxn classification:\n",
    "# ./namerxn -nomap data/mapped_rxn.smi data/classified_rxn.smi\n",
    "\n",
    "# The -nomap I thought would mean that it wouldn't change the atom mapping, yet it clearly did...\n",
    "# I'll just have to trust that namerxn didn't change the order of my reactions, and just append the reaction classes, and finally remove any reactions that couldn't be classified\n",
    "data_df = cleaned_df.copy().reset_index(drop=True)\n",
    "data_df['rxn_class'] = rxn_classes_df['rxn_class']\n",
    "data_df = data_df.dropna(subset=['rxn_class'])\n",
    "data_df.reset_index()\n",
    "print(len(data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419295\n"
     ]
    }
   ],
   "source": [
    "# remove all the unclassified reactions, ie where rxn_class = '0.0'\n",
    "remove_unclassified_rxn_data_df = data_df[~data_df.rxn_class.str.contains(\"0.0\")]\n",
    "print(len(remove_unclassified_rxn_data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Pd in the reagents columns:  1205\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in data_df['reagents_0']:\n",
    "    try:\n",
    "        if 'pd' in i or 'Pd' in i or 'palladium' in i or 'Palladium' in i:\n",
    "            count +=1\n",
    "            #print(i)\n",
    "    except TypeError:\n",
    "        continue\n",
    "print('Number of Pd in the reagents columns: ', count )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a cluster column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['rxn_super_class'] = data_df['rxn_class'].str.rsplit('.', expand=True)[0].astype(int)\n",
    "test_df = data_df['rxn_class'].str.rsplit(';', expand=True)\n",
    "# 2.5% of reactions have been assigned 2 reaction classes. 3 or 4 reaction classes is very rare."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelling_2 import calc_fp\n",
    "from modelling_2 import calc_fp_individual\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from rdkit.rdBase import BlockLogs\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526999/526999 [01:08<00:00, 7655.97it/s]\n",
      "100%|██████████| 526999/526999 [02:21<00:00, 3719.65it/s]\n",
      "100%|██████████| 526999/526999 [02:29<00:00, 3522.12it/s]\n",
      "100%|██████████| 526999/526999 [02:30<00:00, 3500.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 51s, sys: 1min 27s, total: 3min 18s\n",
      "Wall time: 8min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "inputs = tqdm(data_df['product_0'])\n",
    "p0 = Parallel(n_jobs=num_cores)(delayed(calc_fp_individual)(i) for i in inputs)\n",
    "\n",
    "inputs = tqdm(data_df['product_1'])\n",
    "p1 = Parallel(n_jobs=num_cores)(delayed(calc_fp_individual)(i) for i in inputs)\n",
    "\n",
    "inputs = tqdm(data_df['product_2'])\n",
    "p2 = Parallel(n_jobs=num_cores)(delayed(calc_fp_individual)(i) for i in inputs)\n",
    "\n",
    "inputs = tqdm(data_df['product_3'])\n",
    "p3 = Parallel(n_jobs=num_cores)(delayed(calc_fp_individual)(i) for i in inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526999/526999 [00:57<00:00, 9145.03it/s] \n",
      "100%|██████████| 526999/526999 [00:52<00:00, 10127.89it/s]\n",
      "100%|██████████| 526999/526999 [02:11<00:00, 4005.06it/s]\n",
      "100%|██████████| 526999/526999 [02:20<00:00, 3744.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 1min 14s, total: 2min 51s\n",
      "Wall time: 6min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "inputs = tqdm(data_df['reactant_0'])\n",
    "r0 = Parallel(n_jobs=num_cores)(delayed(calc_fp_individual)(i) for i in inputs)\n",
    "\n",
    "inputs = tqdm(data_df['reactant_1'])\n",
    "r1 = Parallel(n_jobs=num_cores)(delayed(calc_fp_individual)(i) for i in inputs)\n",
    "\n",
    "inputs = tqdm(data_df['reactant_2'])\n",
    "r2 = Parallel(n_jobs=num_cores)(delayed(calc_fp_individual)(i) for i in inputs)\n",
    "\n",
    "inputs = tqdm(data_df['reactant_3'])\n",
    "r3 = Parallel(n_jobs=num_cores)(delayed(calc_fp_individual)(i) for i in inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate rxn difference fp\n",
    "# converting one 500k by 2k list to array takes roughly 15s, so the whole thing should take about 2-3 min\n",
    "# need to split into different cells for memory purposes\n",
    "ar_p0 = np.array(p0)\n",
    "ar_p1 = np.array(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_p2 = np.array(p2)\n",
    "ar_p3 = np.array(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_r0 = np.array(r0)\n",
    "ar_r1 = np.array(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_r2 = np.array(r2)\n",
    "ar_r3 = np.array(r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(526999, 2048)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rxn_diff_fp = ar_p0 + ar_p1 + ar_p2 + ar_p3 - ar_r0 - ar_r1 - ar_r2 - ar_r3\n",
    "rxn_diff_fp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to pickle\n",
    "np.save(\"data/ORD_USPTO/USPTO_rxn_diff_fp.pkl\", rxn_diff_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpickle\n",
    "rxn_diff_fp = np.load(\"data/ORD_USPTO/USPTO_rxn_diff_fp.pkl\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one-hot encoding of reagent1_list\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemistry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1a6c9805cce96d1e29a306d4faa1abec69cf2c9ee1771799b926a7cc969fbbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
