{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect datasets for the parameter sharing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read this file:\n",
    "# data/fingerprints/mid_class_train.npy\n",
    "\n",
    "mid_class_train_fp = np.load('../data/fingerprints/mid_class_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271394, 4096)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid_class_train_fp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_class_train_df = pd.read_parquet('../data/mid_class_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271394, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid_class_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', '10', '11', '2', '3', '4', '5', '6', '7', '8', '9'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(mid_class_train_df['super class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2         9\n",
       "3         7\n",
       "4         1\n",
       "5         8\n",
       "7         4\n",
       "         ..\n",
       "356901    1\n",
       "356902    2\n",
       "356903    9\n",
       "356904    1\n",
       "356905    1\n",
       "Name: super class, Length: 271394, dtype: int8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid_class_train_df['super class'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_pfp',\n",
       " 'input_rxnfp',\n",
       " 'concatenate_1',\n",
       " 'input_class',\n",
       " 'param_sharing_layer_1',\n",
       " 'param_sharing_layer_1_switch_case_indexed_case_Identity_0_dropout',\n",
       " 'param_sharing_layer_1_switch_case_indexed_case_Identity_0_dropout_Identity_0_batchnorm',\n",
       " 'fp_transform',\n",
       " 'fp_transform_Relu_0_dropout',\n",
       " 'fp_transform_Relu_0_dropout_dropout_SelectV2_0_batchnorm',\n",
       " 'mol1_h1',\n",
       " 'mol1_h1_Relu_0_dropout',\n",
       " 'mol1_h1_Relu_0_dropout_dropout_SelectV2_0_batchnorm',\n",
       " 'mol1_h2',\n",
       " 'mol1_h2_Tanh_0_dropout',\n",
       " 'mol1_h2_Tanh_0_dropout_Identity_0_batchnorm',\n",
       " 'mol1',\n",
       " 'tf.math.argmax_5',\n",
       " 'tf.one_hot_5',\n",
       " 'tf.stop_gradient_5',\n",
       " 'mol1_dense',\n",
       " 'mol1_dense_Relu_0_dropout',\n",
       " 'mol1_dense_Relu_0_dropout_Identity_0_batchnorm',\n",
       " 'concat_fp_mol1',\n",
       " 'mol2_h1',\n",
       " 'mol2_h1_Relu_0_dropout',\n",
       " 'mol2_h1_Relu_0_dropout_Identity_0_batchnorm',\n",
       " 'mol2_h2',\n",
       " 'mol2_h2_Tanh_0_dropout',\n",
       " 'mol2_h2_Tanh_0_dropout_Identity_0_batchnorm',\n",
       " 'mol2',\n",
       " 'tf.math.argmax_6',\n",
       " 'tf.one_hot_6',\n",
       " 'tf.stop_gradient_6',\n",
       " 'mol2_dense',\n",
       " 'mol2_dense_Relu_0_dropout',\n",
       " 'mol2_dense_Relu_0_dropout_Identity_0_batchnorm',\n",
       " 'concat_fp_mol1_mol2',\n",
       " 'mol3_h1',\n",
       " 'mol3_h1_Relu_0_dropout',\n",
       " 'mol3_h1_Relu_0_dropout_Identity_0_batchnorm',\n",
       " 'mol3_h2',\n",
       " 'mol3_h2_Tanh_0_dropout',\n",
       " 'mol3_h2_Tanh_0_dropout_Identity_0_batchnorm',\n",
       " 'mol3',\n",
       " 'tf.math.argmax_7',\n",
       " 'tf.one_hot_7',\n",
       " 'tf.stop_gradient_7',\n",
       " 'mol3_dense',\n",
       " 'mol3_dense_Relu_0_dropout',\n",
       " 'mol3_dense_Relu_0_dropout_Identity_0_batchnorm',\n",
       " 'concat_fp_mol1_mol2_mol3',\n",
       " 'mol4_h1',\n",
       " 'mol4_h1_Relu_0_dropout',\n",
       " 'mol4_h1_Relu_0_dropout_Identity_0_batchnorm',\n",
       " 'mol4_h2',\n",
       " 'mol4_h2_Tanh_0_dropout',\n",
       " 'mol4_h2_Tanh_0_dropout_Identity_0_batchnorm',\n",
       " 'mol4',\n",
       " 'tf.math.argmax_8',\n",
       " 'tf.one_hot_8',\n",
       " 'tf.stop_gradient_8',\n",
       " 'mol4_dense',\n",
       " 'mol4_dense_Relu_0_dropout',\n",
       " 'mol4_dense_Relu_0_dropout_Identity_0_batchnorm',\n",
       " 'concat_fp_mol1_mol2_mol3_mol4',\n",
       " 'mol5_h1',\n",
       " 'mol5_h1_Relu_0_dropout',\n",
       " 'mol5_h1_Relu_0_dropout_Identity_0_batchnorm',\n",
       " 'mol5_h2',\n",
       " 'mol5_h2_Tanh_0_dropout',\n",
       " 'mol5_h2_Tanh_0_dropout_Identity_0_batchnorm',\n",
       " 'mol5']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['input_pfp', 'input_rxnfp', 'concatenate_1', 'input_class', 'param_sharing_layer_1', 'param_sharing_layer_1_switch_case_indexed_case_Identity_0_dropout', 'param_sharing_layer_1_switch_case_indexed_case_Identity_0_dropout_Identity_0_batchnorm', 'fp_transform', 'fp_transform_Relu_0_dropout', 'fp_transform_Relu_0_dropout_dropout_SelectV2_0_batchnorm', 'mol1_h1', 'mol1_h1_Relu_0_dropout', 'mol1_h1_Relu_0_dropout_dropout_SelectV2_0_batchnorm', 'mol1_h2', 'mol1_h2_Tanh_0_dropout', 'mol1_h2_Tanh_0_dropout_Identity_0_batchnorm', 'mol1', 'tf.math.argmax_5', 'tf.one_hot_5', 'tf.stop_gradient_5', 'mol1_dense', 'mol1_dense_Relu_0_dropout', 'mol1_dense_Relu_0_dropout_Identity_0_batchnorm', 'concat_fp_mol1', 'mol2_h1', 'mol2_h1_Relu_0_dropout', 'mol2_h1_Relu_0_dropout_Identity_0_batchnorm', 'mol2_h2', 'mol2_h2_Tanh_0_dropout', 'mol2_h2_Tanh_0_dropout_Identity_0_batchnorm', 'mol2', 'tf.math.argmax_6', 'tf.one_hot_6', 'tf.stop_gradient_6', 'mol2_dense', 'mol2_dense_Relu_0_dropout', 'mol2_dense_Relu_0_dropout_Identity_0_batchnorm', 'concat_fp_mol1_mol2', 'mol3_h1', 'mol3_h1_Relu_0_dropout', 'mol3_h1_Relu_0_dropout_Identity_0_batchnorm', 'mol3_h2', 'mol3_h2_Tanh_0_dropout', 'mol3_h2_Tanh_0_dropout_Identity_0_batchnorm', 'mol3', 'tf.math.argmax_7', 'tf.one_hot_7', 'tf.stop_gradient_7', 'mol3_dense', 'mol3_dense_Relu_0_dropout', 'mol3_dense_Relu_0_dropout_Identity_0_batchnorm', 'concat_fp_mol1_mol2_mol3', 'mol4_h1', 'mol4_h1_Relu_0_dropout', 'mol4_h1_Relu_0_dropout_Identity_0_batchnorm', 'mol4_h2', 'mol4_h2_Tanh_0_dropout', 'mol4_h2_Tanh_0_dropout_Identity_0_batchnorm', 'mol4', 'tf.math.argmax_8', 'tf.one_hot_8', 'tf.stop_gradient_8', 'mol4_dense', 'mol4_dense_Relu_0_dropout', 'mol4_dense_Relu_0_dropout_Identity_0_batchnorm', 'concat_fp_mol1_mol2_mol3_mol4', 'mol5_h1', 'mol5_h1_Relu_0_dropout', 'mol5_h1_Relu_0_dropout_Identity_0_batchnorm', 'mol5_h2', 'mol5_h2_Tanh_0_dropout', 'mol5_h2_Tanh_0_dropout_Identity_0_batchnorm', 'mol5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total df size:  306427\n"
     ]
    }
   ],
   "source": [
    "# orderly-mid-class dataset size:\n",
    "mid_class_train_path = '../data/mid_class_train.parquet'\n",
    "mid_class_train_df = pd.read_parquet(mid_class_train_path)\n",
    "mid_class_test_path = '../data/mid_class_test.parquet'\n",
    "mid_class_test_df = pd.read_parquet(mid_class_test_path)\n",
    "\n",
    "print('total df size: ', mid_class_train_df.shape[0] + mid_class_test_df.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemistry",
   "language": "python",
   "name": "chemistry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
